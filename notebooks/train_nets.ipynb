{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NET TRAINING\n",
    "\n",
    "A series of experiments (using the images and their corresponding labels and annotations) are performed to select the best parameters to train the final model. The supplementary material of the manuscript includes a table listing the parameters used for this work as a reference. \n",
    "\n",
    "`region` is the name of independent dataset on which to train the machine. In this case, we are showing the data from 'central_Pacific_ocean' located in `basedir`. In this example, we use the region `Central Pacific Ocean` from the provided data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T06:03:43.707974",
     "start_time": "2018-09-29T06:03:41.633558"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels = 40\n"
     ]
    }
   ],
   "source": [
    "##SETUP WORKSPACE \n",
    "import os\n",
    "import reef_learning.experiments.catlin_caffe_experiments as cce\n",
    "import reef_learning.deeplearning_wrappers.catlin_classify as cc\n",
    "import os.path as osp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import reef_learning.deeplearning_wrappers.catlin_caffe_tools as cct\n",
    "import reef_learning.toolbox.plot_log as pl\n",
    "import reef_learning.deeplearning_wrappers.catlin_tools as ct\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "##SET PATHS \n",
    "\n",
    "region='hawaii' #Folder that contrained the data for training the Net.\n",
    "basedir='/media/data_caffe' #directory where the data is stored\n",
    "\n",
    "##Read labelset and check it match your labelset\n",
    "lines = [line.rstrip() for line in open(osp.join(basedir,region,'label_structure.csv'))][1:]\n",
    "labelset = [line.split(',')[1] for line in lines]\n",
    "print 'Number of labels = '+str(len(labelset)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameter optimisation (Experiment sweeper)\n",
    "\n",
    "A series of experiments (using the images and their corresponding labels and annotations) are performed to select the best parameters to train the final model. These parameters include: learning rate (lrate) and receptive field calibration (method). \n",
    "\n",
    "**Learning rate** is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient. The lower the value, the slower we travel along the downward slope. While this might be a good idea (using a low learning rate) in terms of making sure that we do not miss any local minima, it could also mean that we’ll be taking a long time to converge — especially if we get stuck on a plateau region. Here we provide a function ('set_experiment') that evaluates a vector of learning rate values to find the best compromise in accuracy and processing time. \n",
    "\n",
    "**Receptive field** is defined as the region in the input space that a particular CNN’s feature is looking at (i.e. be affected by). When dealing with high-dimensional inputs such as images, it is impractical to connect neurons to all neurons in the previous volume. Instead, we connect each neuron to only a local region of the input volume. The spatial extent of this connectivity is a hyper-parameter called the receptive field of the neuron (equivalently this is the filter size). In the VGG-16 architecture, 224x224 pixels is a predefined area, so it is not possible directly altering the receptive field in this architecture. To go around this point in this work, we vary the size of each image before cropping the patches used for classification and evaluate its impact on the overall classification accuracy. To alter the size, two methods are available: \"scale\", a factor by which the image is increased or decreased without changing the pixel/cm ratio and \"ratio\", changing the pixel/centimetre ratio by interpolation. The later can be change knowing the ratio of the original image, in this case 10 pixel/cm.\n",
    "\n",
    "This experiment sweeper will train multiple models using a combination of learning rates and methods provided and produce a folder for each trained net using a set prefix, defined by 'experiment_type'. \n",
    "\n",
    "    Note: A table in the supplementary material of the manuscript, contains the parameters defined for the results in this publication.  Each experiment can take a day or two, depending on the hardware resources, and uses all the resources from the instance. Therefore, only individual experiments can be run at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-29T08:08:45.199Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 126.07176518  127.70577545  140.36791122]\n",
      "[ 113.68123413  123.70726926  144.58570591]\n",
      "[ 126.07176518  127.70577545  140.36791122]\n",
      "Fine tuning /media/data_caffe/hawaii/ScaleLr_sweeper_scale_1.0_0.001 from vgg_initial.caffemodel.\n"
     ]
    }
   ],
   "source": [
    "#Learning Rate\n",
    "lrate=['0.01',']0.001'\n",
    "#Experiement name (This is the prefix name of the folder that will be create containing the trainned net and its predictions on a small subset of training images, here defined as validation set)\n",
    "experiment_type='ScaleLr_sweeper'\n",
    "#Desired method to explore the importance of receptive field in the classification performance (i.e., scale or ratio)\n",
    "method='scale'\n",
    "# Multiplying factor used to modify the size of the image to evaluate the importance of the receptive field \n",
    "factor=['1.0','2.0']\n",
    "#Number of cycles \n",
    "c=30\n",
    "#Number of iterations per cycle\n",
    "cs=1000\n",
    "       \n",
    "#Run experiment sweeper\n",
    "cce.mix_experiment_wrapper(basedir,\n",
    "                           region,\n",
    "                           method = method, \n",
    "                           factors =  factor,\n",
    "                           etype=experiment_type,\n",
    "                           lrates=lrate, \n",
    "                           cycles=c, \n",
    "                           cyclesize=cs)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

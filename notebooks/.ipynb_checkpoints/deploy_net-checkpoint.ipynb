{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Classify images based on a trained net \n",
    "\n",
    "Here we use the best iteration of a selected Net parameters, based on set of experiments (`training_protocol.pynb`) used to compare the performance of different Net configurations (`Compared_network_configuration.pynb`). In this section, the selected Net will be used to predict lables on a given number of random points from a specified set of images that are contained in a folder called 'data'. For convienience, the folder `data`, within the region folder, contains all the images on which you want to use the Net to estimate the benthic composition. Within this folder, images are organised in subfolders (`img_dir` below) to allow diferent surveys to be processed by different Net, if desired. `img_dir` should contain the images within a folder called `images`. \n",
    "\n",
    "After running the classier on the new images, the scripts will produce a folder called `coverages` that contain a text file for everyimage with location of each point and resulting label classification. Use these files to estimate benthic coverage as described in the manuscript associated to this repository (see `Readme.md`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T22:47:12.749736",
     "start_time": "2018-10-01T22:47:12.202636"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import reef_learning.deeplearning_wrappers.catlin_classify as cc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define data folder to process \n",
    "\n",
    "basedir='/media/data_caffe' #Base directory\n",
    "region='hawaii' #name of folder for the region on which Nets are trained and tested\n",
    "modeldir=osp.join(basedir, region,'ScaleLr_sweeper_scale_1.0_0.001') #directory of the selected Net based on experiment comparisons\n",
    "img_dir=\"to_classify\" # subdirectory containing the images desired to classify using the model defined above. Note that this folder is contained in a folder called data and should contain the images if a subfolder call images.\n",
    "npoints=50 # Total number of points per image used to estimate benthic composition and abundance\n",
    "gpuid=0 #GPU mask id. Change this if you use multiple GPU cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy net on new images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T23:51:09.112776",
     "start_time": "2018-10-01T22:54:39.136426"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLayer initialized with 417 images, 5 imgs per batch, and 224x224 pixel patches\n",
      "Starting /media/data_caffe/hawaii/data/to_classify 660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/beijbom_vision_lib/misc/tools.py:38: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return(im[upper : upper + ps, left : left + ps, :])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done /media/data_caffe/hawaii/data/to_classify 660\n"
     ]
    }
   ],
   "source": [
    "cc.classify_exp(basedir,region,img_dir,modeldir,npoints,force_rewrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once completed, a new folder will be created (`coverages`) that contain the location and classification of the set number of points on each image. Below is the resulting folder structure and a sample of the text files containing the classification of a given image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T23:53:02.029504",
     "start_time": "2018-10-01T23:53:02.017809"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/data_caffe/hawaii/data/to_classify\n",
      "/media/data_caffe/hawaii/data/to_classify/coverages\n",
      "38008151002.jpg.points.csv\n",
      "44013028401.jpg.points.csv\n",
      "44034010001.jpg.points.csv\n",
      "44026218501.jpg.points.csv\n",
      "44005156501.jpg.points.csv\n",
      "/media/data_caffe/hawaii/data/to_classify/images\n",
      "38044022501.jpg\n",
      "44009056101.jpg\n",
      "38045184301.jpg\n",
      "38022039901.jpg\n",
      "44013029501.jpg\n"
     ]
    }
   ],
   "source": [
    "#Resulting file structure\n",
    "for path, dirs, files in os.walk(osp.join(basedir, region,'data',img_dir)):\n",
    "  print path\n",
    "  for f in files[:5]:\n",
    "    print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-02T00:04:55.795450",
     "start_time": "2018-10-02T00:04:55.782323"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row</th>\n",
       "      <th>col</th>\n",
       "      <th>labelcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>429</td>\n",
       "      <td>EAM_DHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>466</td>\n",
       "      <td>575</td>\n",
       "      <td>POR_Com_fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>208</td>\n",
       "      <td>878</td>\n",
       "      <td>EAM_DHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362</td>\n",
       "      <td>537</td>\n",
       "      <td>EAM_DHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>352</td>\n",
       "      <td>913</td>\n",
       "      <td>EAM_DHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row   col    labelcode\n",
       "0   90   429      EAM_DHC\n",
       "1  466   575   POR_Com_fi\n",
       "2  208   878      EAM_DHC\n",
       "3  362   537      EAM_DHC\n",
       "4  352   913      EAM_DHC"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sample from the resulted classification\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "cov_example=os.listdir(osp.join(basedir, region,'data',img_dir,'coverages'))[0]\n",
    "\n",
    "df=pd.read_csv(osp.join(basedir, region,'data',img_dir,'coverages',cov_example),\n",
    "              skiprows=[0])\n",
    "display(df[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "toc": {
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
